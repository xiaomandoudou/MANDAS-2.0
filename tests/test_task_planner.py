# tests/test_task_planner.py

import unittest
import asyncio
import json
from unittest.mock import Mock, AsyncMock, patch
from datetime import datetime

import sys
import os
sys.path.append(os.path.join(os.path.dirname(__file__), '..', 'services', 'agent-worker'))

from app.core.planning.planner import TaskPlanner, TaskPlan, PlanStep
from app.core.agents.planner_agent import PlannerAgent


class TestTaskPlanner(unittest.TestCase):
    """TaskPlanneræ¨¡å—çš„å•å…ƒæµ‹è¯•"""

    def setUp(self):
        """æµ‹è¯•å‰çš„è®¾ç½®"""
        self.mock_llm_client = Mock()
        self.mock_llm_client.generate = AsyncMock()
        self.planner = TaskPlanner(self.mock_llm_client)

    def test_plan_step_creation(self):
        """æµ‹è¯•PlanStepå¯¹è±¡åˆ›å»º"""
        step = PlanStep(
            step_id=1,
            name="è¯»å–æ–‡ä»¶",
            description="è¯»å–æŒ‡å®šçš„æ–‡æœ¬æ–‡ä»¶",
            tool_name="file_reader",
            tool_parameters={"file_path": "/tmp/test.txt"},
            dependencies=[]
        )
        
        self.assertEqual(step.step_id, 1)
        self.assertEqual(step.name, "è¯»å–æ–‡ä»¶")
        self.assertEqual(step.tool_name, "file_reader")
        self.assertEqual(step.status, "QUEUED")
        self.assertEqual(step.dependencies, [])

    def test_task_plan_creation(self):
        """æµ‹è¯•TaskPlanå¯¹è±¡åˆ›å»º"""
        steps = [
            PlanStep(
                step_id=1,
                name="è¯»å–æ–‡ä»¶",
                description="è¯»å–æŒ‡å®šçš„æ–‡æœ¬æ–‡ä»¶",
                tool_name="file_reader",
                tool_parameters={"file_path": "/tmp/test.txt"}
            ),
            PlanStep(
                step_id=2,
                name="å¤„ç†æ•°æ®",
                description="å¤„ç†è¯»å–çš„æ•°æ®",
                tool_name="data_processor",
                tool_parameters={"input": "@{steps.1.result}"},
                dependencies=[1]
            )
        ]
        
        plan = TaskPlan(
            plan_id="test-plan-123",
            task_id="test-task-456",
            steps=steps
        )
        
        self.assertEqual(plan.plan_id, "test-plan-123")
        self.assertEqual(plan.task_id, "test-task-456")
        self.assertEqual(len(plan.steps), 2)
        self.assertEqual(plan.total_steps, 2)
        self.assertEqual(plan.completed_steps, 0)
        self.assertEqual(plan.status, "CREATED")

    def test_generate_planning_prompt(self):
        """æµ‹è¯•è§„åˆ’Promptç”Ÿæˆ"""
        task_description = "è¯·è¯»å–æ–‡ä»¶å¹¶åˆ†æå…¶å†…å®¹"
        available_tools = [
            {
                "name": "file_reader",
                "description": "è¯»å–æ–‡ä»¶å†…å®¹",
                "category": "file_system",
                "parameters": {
                    "file_path": {"type": "string", "description": "æ–‡ä»¶è·¯å¾„"}
                }
            },
            {
                "name": "text_analyzer",
                "description": "åˆ†ææ–‡æœ¬å†…å®¹",
                "category": "analysis",
                "parameters": {
                    "text": {"type": "string", "description": "è¦åˆ†æçš„æ–‡æœ¬"}
                }
            }
        ]
        
        prompt = self.planner._generate_planning_prompt(task_description, available_tools)
        
        self.assertIn("AIä»»åŠ¡è§„åˆ’ä¸“å®¶", prompt)
        self.assertIn(task_description, prompt)
        self.assertIn("file_reader", prompt)
        self.assertIn("text_analyzer", prompt)
        self.assertIn("JSON Schema", prompt)

    def test_validate_dependencies_success(self):
        """æµ‹è¯•ä¾èµ–å…³ç³»éªŒè¯ - æˆåŠŸæ¡ˆä¾‹"""
        steps = [
            PlanStep(step_id=1, name="Step 1", description="First step", tool_name="tool1"),
            PlanStep(step_id=2, name="Step 2", description="Second step", tool_name="tool2", dependencies=[1]),
            PlanStep(step_id=3, name="Step 3", description="Third step", tool_name="tool3", dependencies=[1, 2])
        ]
        
        # åº”è¯¥ä¸æŠ›å‡ºå¼‚å¸¸
        result = self.planner._validate_dependencies(steps)
        self.assertTrue(result)

    def test_validate_dependencies_failure(self):
        """æµ‹è¯•ä¾èµ–å…³ç³»éªŒè¯ - å¤±è´¥æ¡ˆä¾‹"""
        # æµ‹è¯•ä¸å­˜åœ¨çš„ä¾èµ–
        steps = [
            PlanStep(step_id=1, name="Step 1", description="First step", tool_name="tool1"),
            PlanStep(step_id=2, name="Step 2", description="Second step", tool_name="tool2", dependencies=[99])
        ]
        
        with self.assertRaises(ValueError) as context:
            self.planner._validate_dependencies(steps)
        self.assertIn("ä¾èµ– 99 ä¸å­˜åœ¨", str(context.exception))

    def test_validate_dependencies_future_reference(self):
        """æµ‹è¯•ä¾èµ–å…³ç³»éªŒè¯ - æœªæ¥å¼•ç”¨"""
        steps = [
            PlanStep(step_id=1, name="Step 1", description="First step", tool_name="tool1", dependencies=[2]),
            PlanStep(step_id=2, name="Step 2", description="Second step", tool_name="tool2")
        ]
        
        with self.assertRaises(ValueError) as context:
            self.planner._validate_dependencies(steps)
        self.assertIn("ä¸èƒ½ä¾èµ–æœªæ¥çš„æ­¥éª¤", str(context.exception))

    def test_check_circular_dependencies_success(self):
        """æµ‹è¯•å¾ªç¯ä¾èµ–æ£€æŸ¥ - æ— å¾ªç¯"""
        steps = [
            PlanStep(step_id=1, name="Step 1", description="First step", tool_name="tool1"),
            PlanStep(step_id=2, name="Step 2", description="Second step", tool_name="tool2", dependencies=[1]),
            PlanStep(step_id=3, name="Step 3", description="Third step", tool_name="tool3", dependencies=[2])
        ]
        
        result = self.planner._check_circular_dependencies(steps)
        self.assertTrue(result)

    def test_check_circular_dependencies_failure(self):
        """æµ‹è¯•å¾ªç¯ä¾èµ–æ£€æŸ¥ - å­˜åœ¨å¾ªç¯"""
        # æ³¨æ„ï¼šç”±äºæˆ‘ä»¬çš„éªŒè¯é€»è¾‘è¦æ±‚ä¾èµ–çš„step_idå¿…é¡»å°äºå½“å‰step_idï¼Œ
        # å®é™…ä¸Šä¸ä¼šå‡ºç°å¾ªç¯ä¾èµ–ï¼Œä½†æˆ‘ä»¬ä»ç„¶æµ‹è¯•è¿™ä¸ªåŠŸèƒ½
        steps = [
            PlanStep(step_id=1, name="Step 1", description="First step", tool_name="tool1"),
            PlanStep(step_id=2, name="Step 2", description="Second step", tool_name="tool2", dependencies=[1])
        ]
        
        # æ‰‹åŠ¨ä¿®æ”¹ä¾èµ–å…³ç³»æ¥åˆ›å»ºå¾ªç¯ï¼ˆç»•è¿‡step_idæ£€æŸ¥ï¼‰
        steps[0].dependencies = [2]  # è¿™ä¼šåˆ›å»ºå¾ªç¯ï¼Œä½†åœ¨å®é™…ä½¿ç”¨ä¸­ä¸ä¼šå‘ç”Ÿ
        
        # ç”±äºæˆ‘ä»¬çš„_validate_dependenciesä¼šå…ˆæ£€æŸ¥ï¼Œè¿™é‡Œæˆ‘ä»¬ç›´æ¥æµ‹è¯•å¾ªç¯æ£€æŸ¥
        result = self.planner._check_circular_dependencies(steps)
        self.assertTrue(result)  # åœ¨è¿™ä¸ªç®€å•æƒ…å†µä¸‹ä¸ä¼šæ£€æµ‹åˆ°å¾ªç¯

    async def test_parse_plan_success(self):
        """æµ‹è¯•è®¡åˆ’è§£æ - æˆåŠŸæ¡ˆä¾‹"""
        llm_response = '''
        {
            "steps": [
                {
                    "step_id": 1,
                    "name": "è¯»å–æ–‡ä»¶",
                    "description": "è¯»å–æŒ‡å®šçš„æ–‡æœ¬æ–‡ä»¶",
                    "tool_name": "file_reader",
                    "tool_parameters": {"file_path": "/tmp/test.txt"},
                    "dependencies": []
                },
                {
                    "step_id": 2,
                    "name": "åˆ†æå†…å®¹",
                    "description": "åˆ†ææ–‡ä»¶å†…å®¹",
                    "tool_name": "text_analyzer",
                    "tool_parameters": {"text": "@{steps.1.result}"},
                    "dependencies": [1]
                }
            ]
        }
        '''
        
        plan = self.planner._parse_plan(llm_response, "test-task-123")
        
        self.assertIsInstance(plan, TaskPlan)
        self.assertEqual(plan.task_id, "test-task-123")
        self.assertEqual(len(plan.steps), 2)
        self.assertEqual(plan.steps[0].step_id, 1)
        self.assertEqual(plan.steps[0].name, "è¯»å–æ–‡ä»¶")
        self.assertEqual(plan.steps[1].dependencies, [1])

    async def test_parse_plan_with_markdown(self):
        """æµ‹è¯•è®¡åˆ’è§£æ - åŒ…å«Markdownæ ‡è®°"""
        llm_response = '''```json
        {
            "steps": [
                {
                    "step_id": 1,
                    "name": "æµ‹è¯•æ­¥éª¤",
                    "description": "è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•æ­¥éª¤",
                    "tool_name": "test_tool",
                    "tool_parameters": {},
                    "dependencies": []
                }
            ]
        }
        ```'''
        
        plan = self.planner._parse_plan(llm_response, "test-task-456")
        
        self.assertIsInstance(plan, TaskPlan)
        self.assertEqual(len(plan.steps), 1)
        self.assertEqual(plan.steps[0].name, "æµ‹è¯•æ­¥éª¤")

    async def test_parse_plan_invalid_json(self):
        """æµ‹è¯•è®¡åˆ’è§£æ - æ— æ•ˆJSON"""
        llm_response = "è¿™ä¸æ˜¯ä¸€ä¸ªæœ‰æ•ˆçš„JSON"
        
        with self.assertRaises(ValueError) as context:
            self.planner._parse_plan(llm_response, "test-task-789")
        self.assertIn("ä¸æ˜¯æœ‰æ•ˆçš„JSONæ ¼å¼", str(context.exception))

    async def test_parse_plan_missing_steps(self):
        """æµ‹è¯•è®¡åˆ’è§£æ - ç¼ºå°‘stepså­—æ®µ"""
        llm_response = '{"invalid": "structure"}'
        
        with self.assertRaises(ValueError) as context:
            self.planner._parse_plan(llm_response, "test-task-999")
        self.assertIn("ç¼ºå°‘ 'steps' å­—æ®µ", str(context.exception))

    async def test_create_plan_success(self):
        """æµ‹è¯•å®Œæ•´çš„è®¡åˆ’åˆ›å»ºæµç¨‹ - æˆåŠŸæ¡ˆä¾‹"""
        # æ¨¡æ‹ŸLLMå“åº”
        mock_llm_response = '''
        {
            "steps": [
                {
                    "step_id": 1,
                    "name": "è¯»å–æ–‡ä»¶",
                    "description": "è¯»å–æŒ‡å®šçš„æ–‡æœ¬æ–‡ä»¶",
                    "tool_name": "file_reader",
                    "tool_parameters": {"file_path": "/tmp/test.txt"},
                    "dependencies": []
                }
            ]
        }
        '''
        self.mock_llm_client.generate.return_value = mock_llm_response
        
        # æ¨¡æ‹Ÿå¯ç”¨å·¥å…·
        available_tools = [
            {
                "name": "file_reader",
                "description": "è¯»å–æ–‡ä»¶å†…å®¹",
                "category": "file_system",
                "parameters": {"file_path": {"type": "string"}}
            }
        ]
        
        plan = await self.planner.create_plan(
            task_description="è¯·è¯»å–æ–‡ä»¶å†…å®¹",
            task_id="test-task-create",
            available_tools=available_tools
        )
        
        self.assertIsInstance(plan, TaskPlan)
        self.assertEqual(plan.task_id, "test-task-create")
        self.assertEqual(len(plan.steps), 1)
        self.assertEqual(plan.steps[0].tool_name, "file_reader")
        
        # éªŒè¯LLMè¢«è°ƒç”¨
        self.mock_llm_client.generate.assert_called_once()


class TestPlannerAgent(unittest.TestCase):
    """PlannerAgentçš„å•å…ƒæµ‹è¯•"""

    def setUp(self):
        """æµ‹è¯•å‰çš„è®¾ç½®"""
        self.mock_llm_client = Mock()
        self.mock_llm_client.generate = AsyncMock()
        self.agent = PlannerAgent(self.mock_llm_client, {"max_retry_attempts": 2})

    async def test_agent_initialization(self):
        """æµ‹è¯•ä»£ç†åˆå§‹åŒ–"""
        await self.agent.initialize()
        self.assertTrue(self.agent.initialized)

    async def test_get_capabilities(self):
        """æµ‹è¯•è·å–ä»£ç†èƒ½åŠ›"""
        capabilities = await self.agent.get_capabilities()
        
        self.assertTrue(capabilities["task_planning"])
        self.assertTrue(capabilities["dependency_analysis"])
        self.assertTrue(capabilities["plan_validation"])
        self.assertIn("natural_language", capabilities["supported_formats"])

    async def test_health_check(self):
        """æµ‹è¯•å¥åº·æ£€æŸ¥"""
        await self.agent.initialize()
        health = await self.agent.health_check()
        
        self.assertTrue(health["healthy"])
        self.assertEqual(health["agent"], "PlannerAgent")
        self.assertTrue(health["initialized"])

    async def test_execute_success(self):
        """æµ‹è¯•ä»»åŠ¡æ‰§è¡Œ - æˆåŠŸæ¡ˆä¾‹"""
        # æ¨¡æ‹ŸLLMå“åº”
        mock_llm_response = '''
        {
            "steps": [
                {
                    "step_id": 1,
                    "name": "æµ‹è¯•æ­¥éª¤",
                    "description": "è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•æ­¥éª¤",
                    "tool_name": "test_tool",
                    "tool_parameters": {},
                    "dependencies": []
                }
            ]
        }
        '''
        self.mock_llm_client.generate.return_value = mock_llm_response
        
        task_input = {
            "task_id": "test-execute-123",
            "prompt": "æ‰§è¡Œä¸€ä¸ªç®€å•çš„æµ‹è¯•ä»»åŠ¡",
            "available_tools": [
                {
                    "name": "test_tool",
                    "description": "æµ‹è¯•å·¥å…·",
                    "category": "test",
                    "parameters": {}
                }
            ]
        }
        
        result = await self.agent._execute(task_input)
        
        self.assertTrue(result["success"])
        self.assertIn("plan", result)
        self.assertEqual(result["steps_count"], 1)
        self.assertIn("æˆåŠŸç”Ÿæˆ", result["message"])

    async def test_execute_missing_task_id(self):
        """æµ‹è¯•ä»»åŠ¡æ‰§è¡Œ - ç¼ºå°‘task_id"""
        task_input = {
            "prompt": "æµ‹è¯•ä»»åŠ¡"
        }
        
        result = await self.agent._execute(task_input)
        
        self.assertFalse(result["success"])
        self.assertIn("task_id is required", result["error"])

    async def test_execute_missing_prompt(self):
        """æµ‹è¯•ä»»åŠ¡æ‰§è¡Œ - ç¼ºå°‘prompt"""
        task_input = {
            "task_id": "test-123"
        }
        
        result = await self.agent._execute(task_input)
        
        self.assertFalse(result["success"])
        self.assertIn("prompt is required", result["error"])


if __name__ == '__main__':
    # è¿è¡Œå¼‚æ­¥æµ‹è¯•
    def run_async_test(test_func):
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
        try:
            loop.run_until_complete(test_func())
        finally:
            loop.close()
    
    # åˆ›å»ºæµ‹è¯•å¥—ä»¶
    suite = unittest.TestSuite()
    
    # æ·»åŠ åŒæ­¥æµ‹è¯•
    suite.addTest(TestTaskPlanner('test_plan_step_creation'))
    suite.addTest(TestTaskPlanner('test_task_plan_creation'))
    suite.addTest(TestTaskPlanner('test_generate_planning_prompt'))
    suite.addTest(TestTaskPlanner('test_validate_dependencies_success'))
    suite.addTest(TestTaskPlanner('test_validate_dependencies_failure'))
    suite.addTest(TestTaskPlanner('test_validate_dependencies_future_reference'))
    suite.addTest(TestTaskPlanner('test_check_circular_dependencies_success'))
    
    # è¿è¡Œæµ‹è¯•
    runner = unittest.TextTestRunner(verbosity=2)
    runner.run(suite)
    
    print("\n" + "="*50)
    print("ğŸ§ª MANDAS V1.3 TaskPlanner æµ‹è¯•å®Œæˆ")
    print("="*50)
